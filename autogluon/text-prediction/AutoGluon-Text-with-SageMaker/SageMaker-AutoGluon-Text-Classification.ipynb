{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AutoGluon-Text-Classificationを用いたテキスト分類**\n",
    "\n",
    "## **概要**\n",
    "このノートブックでは、AutoGluon-Text-Classificationを用いて日本語のAmazonの商品レビューに対する感情分析を行います。\n",
    "つまり、そのレビューが Positive (Rating が 5 or 4) か、Negative (Rating が 1 or 2)なのかを判定します。\n",
    "これは文書を Positive か Negative に分類する2クラスの分類問題として扱うことができます。\n",
    "\n",
    "AutoGluon-Text-Classificationは、データを用意し、学習時にパラメータを設定するだけでモデルを作成することができます。\n",
    "2020.8時点では、Text-Classificationにはmodelのsave/loadが実装されていません。\n",
    "そこで今回はpickleを用いてモデルのsave/loadを行います。\n",
    "学習には多くのメモリを必要としますので、多くのメモリを利用できるインスタンスを利用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **データの取得**\n",
    "\n",
    "Amazon の商品レビューデータセットは [Registry of Open Data on AWS](https://registry.opendata.aws/) で公開されており、 \n",
    "以下からダウンロード可能です。\n",
    "このノートブックでは、日本語のデータセットをダウンロードします。\n",
    "- データセットの概要  \n",
    "https://registry.opendata.aws/amazon-reviews/\n",
    "\n",
    "- 日本語のデータセット(readme.htmlからたどることができます）  \n",
    "https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\n",
    "\n",
    "以下では、データをダウンロードして解凍 (unzip) します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "download_url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\" \n",
    "dir_name = \"data\"\n",
    "file_name = \"amazon_review.tsv.gz\"\n",
    "tsv_file_name = \"amazon_review.tsv\"\n",
    "file_path = os.path.join(dir_name,file_name)\n",
    "tsv_file_path = os.path.join(dir_name,tsv_file_name)\n",
    "\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File {} already exists. Skipped download.\".format(file_name))\n",
    "else:\n",
    "    urllib.request.urlretrieve(download_url, file_path)\n",
    "    print(\"File downloaded: {}\".format(file_path))\n",
    "    \n",
    "if os.path.exists(tsv_file_path):\n",
    "    print(\"File {} already exists. Skipped unzip.\".format(tsv_file_name))\n",
    "else:\n",
    "    with gzip.open(file_path, mode='rb') as fin:\n",
    "        with open(tsv_file_path, 'wb') as fout:\n",
    "            shutil.copyfileobj(fin, fout)\n",
    "            print(\"File uznipped: {}\".format(tsv_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **データの前処理**\n",
    "\n",
    "ダウンロードしたデータには学習に不要なデータや直接利用できないデータもあります。以下の前処理で利用できるようにします。\n",
    "\n",
    "1. ダウンロードしたデータには不要なデータも含まれているので削除し、2クラス分類 (positive が 1, negative が 0)となるように評価データを加工します。\n",
    "2. 学習データ、テストデータに分けて、保存します。\n",
    "\n",
    "### **データの加工**\n",
    "\n",
    "今回利用しないデータは以下の2つです。必要なデータだけ選んで保存します。\n",
    "- 評価データ `star_rating` と レビューのテキストデータ `review_body` 以外のデータ\n",
    "- 評価が 3 のデータ (positive でも negative でもないデータ)\n",
    "\n",
    "また、評価が1, 2 のデータはラベル 0 (negative) に、評価が4, 5 のデータはラベル 1 (positive) にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(tsv_file_path, sep ='\\t')\n",
    "df_pos_neg = df.loc[:, [\"star_rating\", \"review_body\"]]\n",
    "df_pos_neg = df_pos_neg[df_pos_neg.star_rating != 3]\n",
    "df_pos_neg.loc[df_pos_neg.star_rating < 3, \"star_rating\"] = 0\n",
    "df_pos_neg.loc[df_pos_neg.star_rating > 3, \"star_rating\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020.8 時点では、AutoGluon-Text は csv のみサポートしています。そのため、カンマを含む文章を対象とする際は、文章中のカンマと、文章とラベルを区別するカンマの見分けが付きません。そこで、カンマを含む文章のみをダブルクォーテーション(\")で囲みます。文中にダブルクォーテーションが含まれると正常に処理されないため、まずはそれを除いてから、カンマを含む文章のみにダブルクォーテーションを付与します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_neg[\"review_body\"] = df_pos_neg[\"review_body\"].str.replace(\"\\\"\", \"\")\n",
    "\n",
    "rows_incl_comma = df_pos_neg[\"review_body\"].str.contains(\",\")\n",
    "df_pos_neg.loc[rows_incl_comma, \"review_body\"] = \"\\\"\" + df_pos_neg.loc[rows_incl_comma,\"review_body\"] +\"\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **データの分割**\n",
    "すべてのデータを学習データとすると、データを使って作成したモデルが良いのか悪いのか評価するデータが別途必要になります。 そこで、データを学習データ、テストデータに分割して利用します。学習データはモデルの学習に利用し、最終的に作成されたモデルに対してテストデータによる評価を行います。\n",
    "\n",
    "train_ratio で設定した割合のデータを学習データとし、残ったデータをテストデータに分割して利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dir_name = \"data\"\n",
    "file_name = \"amazon_review.tsv.gz\"\n",
    "tsv_file_name = \"amazon_review.tsv\"\n",
    "file_path = os.path.join(dir_name,file_name)\n",
    "tsv_file_path = os.path.join(dir_name,tsv_file_name)\n",
    "\n",
    "# Swap positions of \"review_body\",\"star_rating\" because transform.py requires this order.\n",
    "labeled_df = df_pos_neg.loc[:, [\"review_body\",\"star_rating\"]]\n",
    "data_size = len(labeled_df.index)\n",
    "train_ratio = 0.9\n",
    "train_index = np.random.choice(data_size, int(data_size*train_ratio), replace=False)\n",
    "test_index = np.setdiff1d(np.arange(data_size), train_index)\n",
    "\n",
    "np.savetxt('train.csv',labeled_df.iloc[train_index].values, fmt=\"%s,%i\") \n",
    "np.savetxt('test.csv',labeled_df.iloc[test_index].values, fmt=\"%s,%i\") \n",
    "\n",
    "print(\"Data is splitted into:\")\n",
    "print(\"Training data: {} records.\".format(len(train_index)))\n",
    "print(\"Test data: {} records.\".format(len(test_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ヘッダの追加**\n",
    "AutoGluon では、データのヘッダを指定して学習することができるため、解析するテキストを`text`、ポジティブかネガティブかを表すラベルを`target`としてヘッダを与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '1s/^/text,target\\n/' train.csv\n",
    "!sed -i '1s/^/text,target\\n/' test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **学習の実行**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **学習データのアップロード**\n",
    "S3にデータをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "s3_train_data = sess.upload_data(path='train.csv', key_prefix='amazon-review-data-csv')\n",
    "print(\"Training data is uploaded to {}\".format(s3_train_data))\n",
    "\n",
    "data_channels = {'train': s3_train_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **学習ジョブの実行**\n",
    "framework_version=\"1.6.0\"を指定して下さい。\n",
    "今回はGPUインスタンスであるml.p3.2xlargeを使用しますが、\n",
    "ml.m4.xlargなどのCPUインスタンスでも学習可能です。\n",
    "ただし、メモリが足りなくなる場合があるため、学習データの件数を減らす必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "gluon_bert = MXNet(\"train_autogluon.py\", \n",
    "                  role=sagemaker.get_execution_role(), \n",
    "                  source_dir = \"src\",\n",
    "                  train_instance_count=1, \n",
    "                  train_instance_type=\"ml.p3.2xlarge\",\n",
    "                  framework_version=\"1.6.0\",\n",
    "                  distributions={'parameter_server': {'enabled': True}},\n",
    "                  py_version = \"py3\",\n",
    "                  hyperparameters={'batch-size': 16, \n",
    "                                   'epochs': 10, \n",
    "                                   'log-interval': 1})\n",
    "\n",
    "gluon_bert.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **デプロイ**\n",
    "学習したモデルをデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = gluon_bert.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **推論**\n",
    "実際の文を用いた推論を行います。\n",
    "\\[1\\]がポジティブ、\\[0\\]がネガティブです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = '子供でも簡単に操作ができて、暇つぶしに最高です。'\n",
    "prediction = predictor.predict([sentence])\n",
    "pred_label = np.argmax(prediction)\n",
    "print('The input sentence sentiment is classified as [%d]. (prbability: %f)' % (pred_label, prediction[0][pred_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **評価**\n",
    "モデルをダウンロードし、テストデータのaccuracyを評価します。\n",
    "メモリを多く必要とするモデルを評価するため、notebookはml.c5.18xlargeなどを使用する必要があります。\n",
    "また、評価の実行に数分かかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **モデルのダウンロード**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $gluon_bert.model_data ./\n",
    "!tar zxvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **関連するライブラリのダウンロード**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade mxnet-cu100\n",
    "!pip install autogluon\n",
    "!pip install gluonnlp==0.8.1\n",
    "!pip install cloudpickle==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **モデルの読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from autogluon import TextClassification as task\n",
    "local_model = pickle.load(open('model', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **テストセットの評価**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = task.Dataset(filepath='test.csv', usecols=['text', 'target'])\n",
    "test_acc = local_model.evaluate(testset)\n",
    "print('Top-1 test acc: %.3f' % test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
